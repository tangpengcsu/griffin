<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <property>
        <name>hive.metastore.warehouse.dir</name>
        <value>hdfs://192.168.50.88:9000/user/hive/warehouse</value>
    </property>

    <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:oracle:thin:@192.168.50.85:1521:orcl</value>
        <description>JDBC connect string for a JDBC metastore</description>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>oracle.jdbc.OracleDriver</value>
        <description>Driver class name for a JDBC metastore</description>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>hive</value>
        <description>Username to use against metastore database</description>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>hive</value>
        <description>password to use against metastore database</description>
    </property>

    <property>
        <name>hive.cli.print.header</name>
        <value>true</value>
        <description>Whether to print the names of the columns in query output.</description>
    </property>

    <property>
        <name>hive.cli.print.current.db</name>
        <value>true</value>
        <description>Whether to include the current database in the Hive prompt.</description>
    </property>

    <property>
        <name>hive.server2.thrift.port</name>
        <value>19999</value>
        <description>Port number of HiveServer2 Thrift interface when hive.server2.transport.mode is 'binary'.
        </description>
    </property>


    <property>  
            <name>datanucleus.readOnlyDatastore</name>  
            <value>false</value>  
    </property>
      
    <property>   
            <name>datanucleus.fixedDatastore</name>  
            <value>false</value>   
    </property>
      
    <property>   
            <name>datanucleus.autoCreateSchema</name>   
            <value>true</value>   
    </property>
      
    <property>  
            <name>datanucleus.autoCreateTables</name>  
            <value>true</value>  
    </property>
      
    <property>  
            <name>datanucleus.autoCreateColumns</name>  
            <value>true</value>  
    </property>
     
    <!--set hive.exec.dynamic.partition=true;(可通过这个语句查看：set hive.exec.dynamic.partition;)
    set hive.exec.dynamic.partition.mode=nonstrict;
    SET hive.exec.max.dynamic.partitions=100000;(如果自动分区数大于这个参数，将会报错)
    SET hive.exec.max.dynamic.partitions.pernode=100000;-->
    <property>
        <name>hive.exec.dynamic.partition</name>
        <value>true</value>
        <description>Whether or not to allow dynamic partitions in DML/DDL.</description>
    </property>

    <property>
        <name>hive.exec.dynamic.partition.mode</name>
        <value>nonstrict</value>
        <description>In strict mode, the user must specify at least one static partition in case the user
            accidentally overwrites all partitions.
        </description>
    </property>
    <property>
        <name>hive.exec.max.dynamic.partitions</name>
        <value>100000</value>
        <description>如果自动分区数大于这个参数，将会报错</description>
    </property>
    <property>
        <name>hive.exec.max.dynamic.partitions.pernode</name>
        <value>100000</value>
        <description></description>
    </property>

</configuration>
